{"forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~bvX6FY5fEeaIFA6Ij_MgHw", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>I guess it should match \"dataset\" value, so like this</text><code>index = \"yelp\"</code><text>Task 3: Topic Modeling eats all 8 Gb of my computer memory with index = \"ceeaus\"</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 113425, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~LG5kso8bEea29BIY1fPlKQ", "createdAt": 1476125755037, "upvoteCount": 1}
{"forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~I02CLbY2Eea0_BJ2t8b8_A", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Hi guys my name is Zhe Du, I am from Maryland. Looking forward to learning from this course and all of you!</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 22938866, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~6QESZMCKEeaVegrLvStXDg", "createdAt": 1481561352856, "upvoteCount": 1}
{"forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~I02CLbY2Eea0_BJ2t8b8_A", "isFlagged": false, "order": 1, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Hi, I'm from Monte Belo, a little city of state of Minas Gerais in Brazil. I'm studing pos-graduate in Bioinformatics and my research is about text mining in biological literature, especially about synthetic and natural drugs used in cancer tratament</text><text>I have an experience on data analysis in R (statistical software). I already Worked with hierarquical clustering.</text><text>One of my main questions is: What software or tecnology do i to use? </text><text>R or Python?</text><text>With R i already have a experience.</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 1, "creatorId": 7751101, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~BhDzJbp2EeaGMhL6_lg_XA", "createdAt": 1480892675206, "upvoteCount": 1}
{"parentForumAnswerId": "bVgqTevEEeWvGQrWsIkLlw~BhDzJbp2EeaGMhL6_lg_XA", "forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~I02CLbY2Eea0_BJ2t8b8_A", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Hi Ramon,</text><text>I saw an optional assignment in C++ for this course.  Below is a link with more info.  C++ is not my strength, but I will look into it in the next few days.</text><text><a href=\"https://www.coursera.org/learn/text-mining/supplement/lNjbq/programming-assignments-overview\">https://www.coursera.org/learn/text-mining/supplement/lNjbq/programming-assignments-overview</a></text><text>You area of study (mining for cancer treatments) looks very exciting and very relevant.</text><text>Daniel</text><text/></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 18855930, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~DKxwULr1EeaN_w7XVB3P7A", "createdAt": 1480947232376, "upvoteCount": 0}
{"forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~UlGrsrvZEeaGMhL6_lg_XA", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Hi,  I have the same doubt as Vincent. When a binary variable has a probability=1 for one of the possible value (strong bias), should the related entropy be zero?</text><text>Thanks in advance,</text><text>Filippo.</text><text/></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 3, "creatorId": 12641252, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~G4wcmr1xEeaT3ArPm3YMvA", "createdAt": 1481220417025, "upvoteCount": 0}
{"forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~UlGrsrvZEeaGMhL6_lg_XA", "isFlagged": false, "order": 1, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Hi,</text><text>I must say that I really encouraged by your careful consideration in taking quiz, \ud83d\ude0a</text><text>Let me know, which expression in the quiz do you think is not true?</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 4102298, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~CmbIYr0gEeaGMhL6_lg_XA", "createdAt": 1481185599249, "upvoteCount": 1}
{"parentForumAnswerId": "bVgqTevEEeWvGQrWsIkLlw~G4wcmr1xEeaT3ArPm3YMvA", "forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~UlGrsrvZEeaGMhL6_lg_XA", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>OK, but as I passed the course, by now I have no access to the mentioned quiz, but the entropy of binary varaible equals to one, iff it is fully unbiased, p(X=1)=p(X=0)</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 4102298, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~0EVh6L3KEealvA6gwFIz4g", "createdAt": 1481258945663, "upvoteCount": 0}
{"parentForumAnswerId": "bVgqTevEEeWvGQrWsIkLlw~G4wcmr1xEeaT3ArPm3YMvA", "forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~UlGrsrvZEeaGMhL6_lg_XA", "isFlagged": false, "order": 1, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Arefeh,</text><text>This is all well and good but it does not resolve the problem.  Yes, there is one degree of freedom, so if X=1 is a constant so is X=0.  Second, if a variable is constant entropy is zero by definition.  In question number nine there are two responses where the binary variable is constant and the claim is that entropy is one.  The problem is that there are two false answers, and the students are ask to pick which one answer is NOT true.</text><text/><text>I hope this helps.</text><text>Vince</text><text/></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 172542, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~1jeTTb2SEeaVegrLvStXDg", "createdAt": 1481234903822, "upvoteCount": 1}
{"parentForumAnswerId": "bVgqTevEEeWvGQrWsIkLlw~G4wcmr1xEeaT3ArPm3YMvA", "forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~UlGrsrvZEeaGMhL6_lg_XA", "isFlagged": false, "order": 2, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Hi Filippo,</text><text>Please consider the following computation of entropy X, like as the situation you mentioned for the binary varaible :</text><text>H(X) = -(p(X=1)*log(p(X=1))+p(X=0)*log(p(X=0)))=</text><text>-(1*log1 + 0*log0 )= -(1*0 + 0) = 0 \ud83d\ude0a</text><text>These notes, which used in the above proof may be useful:</text><text>Log 1 = 0 : </text><text>For binary varaible we have: p(X=1)+p(X=0) =1 , and in our case: p(X=1)=1, so p(X=0)=0</text><text>Please ask again, if my proof is not clear enough\ud83d\ude03</text><text>I think this intuitive explaination could be useful for you, too: </text><text>Intuitively, Entropy is a measure of how likly that an event be a news, when you know that an event surly happen, it's not news, so the entropy of that event  is minimum, which is 0</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 4102298, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~HcDvEL13Eea0_BJ2t8b8_A", "createdAt": 1481222997932, "upvoteCount": 1}
{"forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~tnHmbbv4EeaIRw7T1E5tHA", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>thank you for your Answer...</text><text>But what i mean is in similarity function...I understood IDF formula what i didn't get is in similarity function when we compute dot product is between Xi   and Yi and that refere to diff\u00e9rents word from different context and this words  might be different too........then, when we need multiply with IDF(wi) which Idf i compute ??? i mean of which word??? IDF(wi) ----&gt; this wi of first context  or second context????</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 2, "creatorId": 1230929, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~ZHhVVr1bEeaGMhL6_lg_XA", "createdAt": 1481211090666, "upvoteCount": 0}
{"forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~tnHmbbv4EeaIRw7T1E5tHA", "isFlagged": false, "order": 1, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Hi Latifa,</text><text>Could you please mention the IDF formula, which you mean?</text><text>The IDF formula generally has the form like that:</text><text>IDF(w) = Log(N/df(w))</text><text>In different applications or similar functions, we have some small changes in this form,</text><text>If you mention the similarity function you mean, I can exactly explain you in details,</text><text>But, overally I must say that , yes, different Content have different  words, but IDF computes for each word w, in a collection of docs, in more details, I must say that IDF(w) is the number of collection docs (: N) over the number of docs in collection which contain the word w (: df(w)),</text><text>I hope that is helps!</text><text>If my explaination is not enough, let me know... \ud83d\ude03</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 4102298, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~Nbwk6b0eEeaVegrLvStXDg", "createdAt": 1481184812957, "upvoteCount": 0}
{"parentForumAnswerId": "bVgqTevEEeWvGQrWsIkLlw~ZHhVVr1bEeaGMhL6_lg_XA", "forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~tnHmbbv4EeaIRw7T1E5tHA", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Thank you very much to take time and make similarity fonction clear to me ...:)  May God reward you for ur help   </text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 1230929, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~0_56DL1yEeatew7zqUaXxg", "createdAt": 1481221156197, "upvoteCount": 0}
{"parentForumAnswerId": "bVgqTevEEeWvGQrWsIkLlw~ZHhVVr1bEeaGMhL6_lg_XA", "forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~tnHmbbv4EeaIRw7T1E5tHA", "isFlagged": false, "order": 1, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>OK, Suppose we want to compute dot product similarity function between two documents, ex. doc A and doc B.</text><text>We make a vector of length |V|, ( V is a set of our vocabularies) , for each doc. In your example this vectors are X and Y.</text><text>Every element of these vectors refer to one definite word, so Xi and Yi are the same word, because of their same indices, but are in different document. </text><text>Idf(w) for each word w is equal, idf is independent of content of each individual document, it is the quantity which conputed just for each word, not dependent on document. So, no difference between computation of idf of word w in first or second doc, because the definition of idf is independent of which doc contains w.</text><text>I think you specifically mean that is not a good definition of idf, because words with same dictation could be different in different Content, yes, that's a correct! </text><text>But idf is a simple measure, which want to just recognise special words, it has some problems like as you mentioned. In this cases that you emphasis on, word disambiguation technique s could be useful, also the representation of word like which word2vec uses, maybe useful, but it depends on the application. Because word disambiguation could be costly.</text><text>Thank you for your careful consideration about IDF!\ud83d\ude0a\ud83d\ude0a</text><text>If my explaination is not enough for you to get answer, let me to know, again!! \ud83d\ude03</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 4102298, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~Bz8DbL1nEeaVegrLvStXDg", "createdAt": 1481216088223, "upvoteCount": 2}
{"forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~R_h8KK77Eeabrw6CQe0vwA", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Good suggestion. I'll pass it along. Thanks!</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 1, "creatorId": 18913600, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~RRreKLW3EeaP2goq4S49oA", "createdAt": 1480370942441, "upvoteCount": 1}
{"parentForumAnswerId": "bVgqTevEEeWvGQrWsIkLlw~RRreKLW3EeaP2goq4S49oA", "forumQuestionId": "bVgqTevEEeWvGQrWsIkLlw~R_h8KK77Eeabrw6CQe0vwA", "isFlagged": false, "order": 0, "content": {"typeName": "cml", "definition": {"value": "<co-content><text>Would there be any chance for that soon?</text></co-content>", "dtdId": "discussion/1"}}, "state": {}, "childAnswerCount": 0, "creatorId": 139781, "isUpvoted": false, "id": "105956~bVgqTevEEeWvGQrWsIkLlw~klz1yrlAEeaT3ArPm3YMvA", "createdAt": 1480759766599, "upvoteCount": 0}
